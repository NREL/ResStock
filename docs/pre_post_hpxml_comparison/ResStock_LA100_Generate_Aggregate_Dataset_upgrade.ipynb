{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the \"Aggregate Dataset\" for LA100 - Upgrades\n",
    "\n",
    "This notebook compares the total stock results of two upgrade runs, both have an upgrade to min eff MSHP from window AC:\n",
    "* resstock-old (pre-HPXML) SHA: 08aa4eb3cc20908415fad631c8cbe9c29541d001 (04/08/2022)\n",
    "* HPXML: SHA: 5f3f50fce1f45bc69fd60ad0f2276c464d4ba717 (04/09/2022)\n",
    "\n",
    "yaml files available in la100es-resstock: https://github.com/NREL/la100es-resstock/tree/ll/pre-post-hpxml-comparison-runs/project_la\n",
    "\n",
    "### 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from eulpda.smart_query.EULPAthena import EULPAthena\n",
    "import eulpcv.resstock_enduse_categories as enduse_categories\n",
    "import eulpcv.hpxml_resstock_enduse_categories as hpxml_enduse_categories\n",
    "\n",
    "from make_la100_dataset import AggregateDataLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\".\").resolve() / \"data\" / \"la100_upgrades\"\n",
    "datadir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"data directory: {datadir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. get simulated data - baseline and upgrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_type = \"upgrades\" # <---- baseline or upgrades # if baseline, subset to those with applicable to upgrade only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. Get - Old ResStock run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enduses_not_available = [\n",
    "    'electricity_central_system_pumps_heating_kwh', \n",
    "    'electricity_central_system_pumps_cooling_kwh',\n",
    "    'electricity_central_system_heating_kwh',\n",
    "    'electricity_central_system_cooling_kwh',\n",
    "    ]\n",
    "enduse_dict = {key:val for key, val in enduse_categories.enduse_category_dict().items() if key not in enduses_not_available}\n",
    "enduses = list(enduse_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"2012_old_resstock_mshp_run\"\n",
    "file = datadir / f\"{table_name}_{sim_type}_15min_timeseries.csv\"\n",
    "\n",
    "if file.exists():\n",
    "    df_sim = pd.read_csv(file, parse_dates=[\"time\"])\n",
    "\n",
    "else:\n",
    "    # [1] Initialize Athena object\n",
    "    Athena = EULPAthena(\n",
    "        workgroup='eulp',\n",
    "        db_name='la-100',\n",
    "        buildstock_type='resstock',\n",
    "        table_name=table_name,\n",
    "    )\n",
    "\n",
    "    # [2] Get applicable building_id\n",
    "    query = f\"\"\"\n",
    "    SELECT \"building_id\" FROM \"{table_name}_upgrades\"\n",
    "    WHERE \"upgrade\" = '1' AND \"completed_status\" = 'Success' AND \"apply_upgrade.applicable\" = true\n",
    "    \"\"\"\n",
    "    bldgs = Athena.execute(query)\n",
    "    print(f\"{table_name} has {len(bldgs)} bldgs with upgrade applied\")\n",
    "\n",
    "    # [3] Get aggregates\n",
    "    restrict = [\n",
    "        (\"completed_status\",['Success']), \n",
    "        (f'\"{table_name}_timeseries\".\"building_id\"', bldgs[\"building_id\"].to_list())\n",
    "        ]\n",
    "    if sim_type == \"baseline\":\n",
    "        restrict.append(\n",
    "            (f'\"{table_name}_timeseries\".\"upgrade\"', ['0'])\n",
    "        )\n",
    "    else:\n",
    "        restrict.append(\n",
    "            (f'\"{table_name}_timeseries\".\"upgrade\"', ['1'])\n",
    "        )\n",
    "    query = Athena.aggregate_timeseries(\n",
    "            enduses = enduses,\n",
    "            group_by = ['time'],\n",
    "            order_by = ['time'],\n",
    "            restrict = restrict,\n",
    "            get_query_only=True,\n",
    "        )\n",
    "    df_sim = Athena.execute(query)\n",
    "    \n",
    "    # adjustment - kwh_per_unit\n",
    "    for eu in enduses:\n",
    "        df_sim[eu] = df_sim[eu].divide(df_sim[\"scaled_unit_count\"])\n",
    "\n",
    "    df_sim = df_sim.drop(columns=[\"scaled_unit_count\"])\n",
    "    df_sim.to_csv(file, index=False)\n",
    "   \n",
    "df_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reduce data dimensions\n",
    "df_sim = AggregateDataLA.resample_data(df_sim, freq='1h', make_period_beginning=True, count_cols=[\"raw_count\"])\n",
    "df_sim = AggregateDataLA.combine_end_uses(df_sim, enduse_dict)\n",
    "\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Get - HPXML run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enduse_dict2 = hpxml_enduse_categories.enduse_category_dict()\n",
    "enduses2 = hpxml_enduse_categories.enduse_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name2 = \"2012_hpxml_mshp_run\"\n",
    "file2 = datadir / f\"{table_name2}_{sim_type}_15min_timeseries.csv\"\n",
    "\n",
    "if file2.exists():\n",
    "    df_sim2 = pd.read_csv(file2, parse_dates=[\"time\"])\n",
    "\n",
    "else:\n",
    "    # [1] Initialize Athena object\n",
    "    Athena2 = EULPAthena(\n",
    "        workgroup='eulp',\n",
    "        db_name='la-100',\n",
    "        buildstock_type='resstock',\n",
    "        table_name=table_name2,\n",
    "    )\n",
    "\n",
    "    # [2] Get applicable building_id\n",
    "    query2 = f\"\"\"\n",
    "    SELECT \"building_id\" FROM \"{table_name2}_upgrades\"\n",
    "    WHERE \"upgrade\" = '1' AND \"completed_status\" = 'Success' AND \"apply_upgrade.applicable\" = true\n",
    "    \"\"\"\n",
    "    bldgs2 = Athena2.execute(query2)\n",
    "    print(f\"{table_name2} has {len(bldgs2)} bldgs with upgrade applied\")\n",
    "\n",
    "    # [3] Get aggregates\n",
    "    restrict = [\n",
    "        (\"completed_status\",['Success']), \n",
    "        (f'\"{table_name2}_timeseries\".\"building_id\"', bldgs2[\"building_id\"].to_list())\n",
    "        ]\n",
    "    if sim_type == \"baseline\":\n",
    "        restrict.append(\n",
    "            (f'\"{table_name2}_timeseries\".\"upgrade\"', ['0'])\n",
    "        )\n",
    "    else:\n",
    "        restrict.append(\n",
    "            (f'\"{table_name2}_timeseries\".\"upgrade\"', ['1'])\n",
    "        )\n",
    "    query2 = Athena2.aggregate_timeseries(\n",
    "            enduses = enduses2,\n",
    "            group_by = ['time'],\n",
    "            order_by = ['time'],\n",
    "            restrict = restrict,\n",
    "            get_query_only=True,\n",
    "        )\n",
    "    df_sim2 = Athena2.execute(query2)\n",
    "\n",
    "    # adjustment - kwh_per_unit\n",
    "    for eu in enduses2:\n",
    "        df_sim2[eu] = df_sim2[eu].divide(df_sim2[\"scaled_unit_count\"])\n",
    "\n",
    "    df_sim2 = df_sim2.drop(columns=[\"scaled_unit_count\"])\n",
    "    df_sim2.to_csv(file2, index=False)\n",
    "   \n",
    "df_sim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reduce data dimensions\n",
    "df_sim2 = AggregateDataLA.resample_data(df_sim2, freq='1h', make_period_beginning=True, count_cols=[\"raw_count\"])\n",
    "df_sim2 = AggregateDataLA.combine_end_uses(df_sim2, enduse_dict2)\n",
    "\n",
    "df_sim2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare end use plots between Old-ResStock and HPXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting paras\n",
    "\n",
    "# from visualization_notebook\n",
    "seasons = {\n",
    "    \"summer_months\": [5, 6, 7, 8, 9],\n",
    "    \"shoulder_months\": [4, 10, 11],\n",
    "    \"winter_months\": [1, 2, 3, 12],\n",
    "}\n",
    "\n",
    "# from EZVIZ\n",
    "color_list = [\n",
    "                '#F7DF10',  # Interior Lighting\n",
    "                '#DEC310',  # Exterior Lighting\n",
    "                '#4A4D4A',  # Plug Loads\n",
    "                '#29AAE7',  # Refrigerator\n",
    "                '#3cb6f0',  # Extra Refrigerator\n",
    "                '#59caff',  # Freezer\n",
    "                '#51e889',  # Clothes Washer\n",
    "                '#FF79AD',  # Clothes Dryer\n",
    "                '#D3D3D3',  # Dishwasher\n",
    "                '#ff2200',  # Cooking Range\n",
    "                '#632C94',  # Well Pump\n",
    "                '#ff7300',  # Pool/Spa Pump\n",
    "                '#FFB239',  # Hot Water\n",
    "                '#C0C0C0',  # Ceiling Fan\n",
    "                '#FF79AD',  # Vent Fans\n",
    "                '#632C94',  # HVAC Fan/Pump\n",
    "                '#0071BD',  # Cooling\n",
    "                '#EF1C21',  # Heating\n",
    "                '#1adb61',  # Electric Vehicle\n",
    "                '#4748a8'  # PV\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up data\n",
    "metric = \"kwh_per_unit\"\n",
    "enduses = [x for x in enduse_categories.abbreviated_enduse_list() if x != \"total\"]\n",
    "\n",
    "df_plot = df_sim.set_index([\"timestamp\"])[[x for x in enduses if x in df_sim.columns]]\n",
    "df_plot2 = df_sim2.set_index([\"timestamp\"])[[x for x in enduses if x in df_sim2.columns]]\n",
    "\n",
    "ymin = min(\n",
    "    df_plot[\"pv\"].min(),\n",
    "    df_plot2[\"pv\"].min()\n",
    ")*1.2\n",
    "ymax = max(\n",
    "    df_plot.sum(axis=1).max(),\n",
    "    df_plot2.sum(axis=1).max()\n",
    ")*0.75\n",
    "print(f\"ymin: {ymin}, ymax: {ymax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "print(f\"Min-eff MSHP Upgrde: {sim_type}\")\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "fig_n = 0\n",
    "for season in seasons:\n",
    "    ### [1] ###\n",
    "    fig_n = fig_n + 1\n",
    "    ax = plt.subplot(3, 2, fig_n)\n",
    "    sim_run = \"Old-ResStock\"\n",
    "\n",
    "    df_diurnal = df_plot.loc[df_plot.index.month.isin(seasons[season])]\n",
    "    df_diurnal = df_diurnal.groupby(df_diurnal.index.hour).mean()\n",
    "    missing_enduses = list(set(enduses).difference(set(df_diurnal.columns)))\n",
    "    if missing_enduses:\n",
    "        for eu in missing_enduses:\n",
    "            df_diurnal[eu] = np.nan\n",
    "    df_diurnal[enduses].plot(kind=\"area\", stacked=True, ax=ax, color=color_list, legend=False, ls='None')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim(ymin=ymin, ymax=ymax)\n",
    "    ax.margins(x=0)\n",
    "    ax.set_xticks(np.arange(df_diurnal.index[0], df_diurnal.index[-1], 3))\n",
    "    ax.set_title(f'{sim_run}-{season}')\n",
    "\n",
    "    ### [2] ###\n",
    "    fig_n = fig_n + 1\n",
    "    ax = plt.subplot(3, 2, fig_n)\n",
    "    sim_run2 = \"HPXML\"\n",
    "\n",
    "    df_diurnal2 = df_plot2.loc[df_plot2.index.month.isin(seasons[season])]\n",
    "    df_diurnal2 = df_diurnal2.groupby(df_diurnal2.index.hour).mean()\n",
    "    missing_enduses = list(set(enduses).difference(set(df_diurnal2.columns)))\n",
    "    if missing_enduses:\n",
    "        for eu in missing_enduses:\n",
    "            df_diurnal2[eu] = np.nan\n",
    "            \n",
    "    df_diurnal2[enduses].plot(kind=\"area\", stacked=True, ax=ax, color=color_list, legend=False, ls='None')\n",
    "    ax.set_ylim(ymin=ymin, ymax=ymax)\n",
    "    ax.margins(x=0)\n",
    "    ax.set_xticks(np.arange(df_diurnal2.index[0], df_diurnal2.index[-1], 3))\n",
    "    ax.set_title(f'{sim_run2} - {season}')\n",
    "    \n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles[::-1], labels[::-1], loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "fig.tight_layout()\n",
    "\n",
    "figfile = datadir / f\"enduse_comparison_{sim_type}.pdf\"\n",
    "fig.savefig(figfile)\n",
    "\n",
    "print(f'{sim_run}: {df_sim[\"raw_count\"].mean()}')\n",
    "print(f'{sim_run2}: {df_sim2[\"raw_count\"].mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EULP-calibration-and-validation",
   "language": "python",
   "name": "eulp-calibration-and-validation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
